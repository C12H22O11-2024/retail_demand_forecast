{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "BZ8790LLHxV7"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/C12H22O11-2024/retail_demand_forecast/blob/main/20250812_Course_project_Data_Extraction_Time_series_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries & Load Data\n"
      ],
      "metadata": {
        "id": "CzCdNUpriIbh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Required Packages"
      ],
      "metadata": {
        "id": "IGAyzheKh0qJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U gdown # Upgrade/install gdown for downloading files from Google Drive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQIlJmHPZpxS",
        "outputId": "2f3cc327-e3cf-4c4d-ecc3-2d987260ae91"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.8.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import necessary libraries"
      ],
      "metadata": {
        "id": "_mNLK02WiRQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data manipulation & analysis\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "x_2o9nLsG7v_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "gperJEJridlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Access Google Drive from Colab\n",
        "from google.colab import drive\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "9_KZvhyuY9Ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Helper\n",
        "import gdown"
      ],
      "metadata": {
        "id": "B665aPpWihbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kjsK4z-KihYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configurations"
      ],
      "metadata": {
        "id": "e-WVxTlNplDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary mapping filenames to their Google Drive file IDs\n",
        "file_information = {\n",
        "    \"stores.csv\": \"1heKGso4BXMzi4PMY2A_Csb2m-KiuwRxu\",\n",
        "    \"items.csv\": \"1bTB2mV8WdK97zMgXK36hxSysThQ7yIvG\",\n",
        "    \"transactions.csv\": \"1-2i5naktdTZn-EwEfurCQ-qjK1unAGPc\",\n",
        "    \"oil.csv\": \"15JROHp1gVy9E5P_L_-oUUcx9xmMNQw6l\",\n",
        "    \"holidays_events.csv\": \"1yBky_3tA-oXUPC-2QNtDAKqk9bqPY16E\"\n",
        "}"
      ],
      "metadata": {
        "id": "-GrHXl2wpn6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_file_id = \"1s4fhVpD1oEnixZSi1WtnexaYJJNjKyOc\""
      ],
      "metadata": {
        "id": "D0hKEmVSpn3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the item families we want to filter: 'GROCERY I', 'BEVERAGES', 'CLEANING'\n",
        "item_families = ['GROCERY I', 'BEVERAGES', 'CLEANING']"
      ],
      "metadata": {
        "id": "CCRmCPZapn1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select data before April'14\n",
        "max_date = '2014-04-01'"
      ],
      "metadata": {
        "id": "LYrX9PLwqB0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chunk size\n",
        "chunk_size = 10**6"
      ],
      "metadata": {
        "id": "sL6mdwokpnqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Google Drive"
      ],
      "metadata": {
        "id": "uAwVJvipileU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')  # Mount drive to access dataset files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8To-sD0iq3p",
        "outputId": "cb5fdacd-f575-4ef6-f611-5fa80e2aa5c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Smaller CSV Files from Google Drive"
      ],
      "metadata": {
        "id": "u8UBoBZjiwjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download each file from Google Drive using gdown\n",
        "for output, file_id in file_information.items():\n",
        "    url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "    gdown.download(url, output, quiet=False)"
      ],
      "metadata": {
        "id": "R3rh_IJpZInZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Downloaded Smaller CSV Files into DataFrames"
      ],
      "metadata": {
        "id": "BST6vXXNi7Nw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_stores = pd.read_csv(\"stores.csv\")\n",
        "df_items = pd.read_csv(\"items.csv\")\n",
        "df_transactions = pd.read_csv(\"transactions.csv\")\n",
        "df_oil = pd.read_csv(\"oil.csv\")\n",
        "df_holidays_events = pd.read_csv(\"holidays_events.csv\")"
      ],
      "metadata": {
        "id": "_Xt4uUtgZRMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load & Filter train.csv in Chunks\n"
      ],
      "metadata": {
        "id": "bhaKk7rOHj0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download train.csv file from Google Drive\n",
        "url = f\"https://drive.google.com/uc?id={train_file_id}\"\n",
        "\n",
        "output = \"train.csv\"  # will be saved in Colabâ€™s temp storage\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "# Filter store numbers for the 'Guayas' state\n",
        "# Extract the unique store numbers from the 'Guayas' state in the stores dataframe\n",
        "store_ids = df_stores[df_stores['state'] == 'Guayas']['store_nbr'].unique()\n",
        "\n",
        "# Get item numbers that belong to the specified item families\n",
        "items_ids = df_items[df_items['family'].isin(item_families)]\n",
        "\n",
        "# Create an empty list to store filtered chunks of data\n",
        "filtered_chunks = []\n",
        "\n",
        "# Loop through each chunk of data (for large dataset processing)\n",
        "for chunk in pd.read_csv(output, chunksize=chunk_size, parse_dates=[\"date\"]):\n",
        "    # Filter the chunk based on store numbers, item numbers\n",
        "    # Conditions:\n",
        "    # - Store numbers should be in 'Guayas' state\n",
        "    # - Item numbers should belong to the selected item families\n",
        "    chunk_filtered = chunk[(chunk['store_nbr'].isin(store_ids))]\n",
        "    chunk_filtered = chunk_filtered[(chunk_filtered['date'] < max_date)]\n",
        "    chunk_filtered = chunk_filtered.merge(items_ids, on=\"item_nbr\", how=\"inner\")\n",
        "\n",
        "    # Append the filtered chunk to the list of filtered chunks\n",
        "    filtered_chunks.append(chunk_filtered)\n",
        "\n",
        "    # Delete the chunk to free up memory (important for large datasets)\n",
        "    del chunk\n",
        "\n",
        "# Combine all filtered chunks into a single DataFrame\n",
        "df_train = pd.concat(filtered_chunks, ignore_index=True)\n",
        "\n",
        "# Clean up the memory by deleting the list of filtered chunks\n",
        "del filtered_chunks"
      ],
      "metadata": {
        "id": "pxkhWXdfaBBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial Data Checks"
      ],
      "metadata": {
        "id": "5UmMqVWEjQJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "id": "2f8_ENTiYK3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape"
      ],
      "metadata": {
        "id": "bJu8j8D-XpyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.describe()"
      ],
      "metadata": {
        "id": "3jQ6XVDNXvjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.info()"
      ],
      "metadata": {
        "id": "3-dDfXZ-37Bw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.duplicated().sum()"
      ],
      "metadata": {
        "id": "toy-K5U03E1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Missing Values Check & Handling"
      ],
      "metadata": {
        "id": "fi9YXuDTHm1k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check for Missing Values"
      ],
      "metadata": {
        "id": "XedCRX0_jyWb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Missing values in train dataset:\")\n",
        "print(df_train.isna().sum(), '\\n')  # Checking missing values in df_train"
      ],
      "metadata": {
        "id": "ambUtMImHBdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Missing values in oil dataset:\")\n",
        "print(df_oil.isna().sum(), '\\n')  # Checking missing values in df_oil"
      ],
      "metadata": {
        "id": "ciw2rcqTjmNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Missing values in transactions dataset:\")\n",
        "print(df_transactions.isna().sum(), '\\n')  # Checking missing values in df_transactions"
      ],
      "metadata": {
        "id": "FPzBtp8QjmLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Missing values in holidays_events dataset:\")\n",
        "print(df_holidays_events.isna().sum(), '\\n')  # Checking missing values in df_holidays_events"
      ],
      "metadata": {
        "id": "pPGStnK8jmJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Missing values in items dataset:\")\n",
        "print(df_items.isna().sum(), '\\n')  # Checking missing values in df_items"
      ],
      "metadata": {
        "id": "uOzgcOyljmGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Missing values in stores dataset:\")\n",
        "print(df_stores.isna().sum(), '\\n')  # Checking missing values in df_stores"
      ],
      "metadata": {
        "id": "VZZaTngDjmEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OXwX8PBajmB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handling of Missing Values"
      ],
      "metadata": {
        "id": "S0iv2rTNj5Zu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values in `onpromotion` column in df_train\n",
        "df_train['onpromotion'] = df_train['onpromotion'].fillna(False).astype(bool)  # Assuming missing means not on promotion"
      ],
      "metadata": {
        "id": "ASFhDGaDjl_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values in `dcoilwtico` column in df_oil using backward fill (bfill)\n",
        "df_oil['dcoilwtico'] = df_oil['dcoilwtico'].bfill()  # Using the next valid value to fill missing oil prices"
      ],
      "metadata": {
        "id": "ivVAHg6Yjl85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dS5JZW25jl6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verification of Missing Values after Handling"
      ],
      "metadata": {
        "id": "PxoLQ717kBVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Missing values in train dataset after handling:\")\n",
        "print(df_train.isna().sum(), '\\n')"
      ],
      "metadata": {
        "id": "2PnajSzVjl4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Missing values in oil dataset after handling:\")\n",
        "print(df_oil.isna().sum(), '\\n')"
      ],
      "metadata": {
        "id": "60Y4cEsejl2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pIwumVPljlz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning"
      ],
      "metadata": {
        "id": "kzRCBs66kr-_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handle Negative Sales (Returns)"
      ],
      "metadata": {
        "id": "BZ8790LLHxV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify negative sales before correction\n",
        "negative_sales_before = df_train[df_train['unit_sales'] < 0]\n",
        "print(\"Negative sales before correction:\")\n",
        "print(negative_sales_before.head(), '\\n')\n"
      ],
      "metadata": {
        "id": "fxu6N-UaHIWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace negative sales with 0 (treat returns as no sales)\n",
        "df_train['unit_sales'] = df_train['unit_sales'].apply(lambda x: max(x, 0))"
      ],
      "metadata": {
        "id": "WK5NimVEkz0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify that there are no negative sales after correction\n",
        "negative_sales_after = df_train[df_train['unit_sales'] < 0]\n",
        "if negative_sales_after.empty:\n",
        "    print(\"All negative sales have been corrected successfully.\")\n",
        "else:\n",
        "    print(\"Negative sales still present after correction:\")\n",
        "    print(negative_sales_after.head())"
      ],
      "metadata": {
        "id": "fTYqVY88kzvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape"
      ],
      "metadata": {
        "id": "Pd-9hTX9j3VW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check Unique Stores & Items"
      ],
      "metadata": {
        "id": "UUrFeUQqIKgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print unique stores in filtered data compared to original\n",
        "print(f\"Unique stores in filtered data: {df_train['store_nbr'].nunique()} out of {df_stores['store_nbr'].nunique()} stores in the original dataset.\")"
      ],
      "metadata": {
        "id": "m_Ry660QHML1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print unique items in filtered data compared to original\n",
        "print(f\"Unique items in filtered data: {df_train['item_nbr'].nunique()} out of {df_items['item_nbr'].nunique()} items in the original dataset.\")"
      ],
      "metadata": {
        "id": "CEprK13ml3VF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detect & Handle Outliers Using Z-Score"
      ],
      "metadata": {
        "id": "0CntXM6DH1_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute mean and standard deviation for each store-item group\n",
        "mean_sales = df_train.groupby(['store_nbr', 'item_nbr'])['unit_sales'].transform('mean')\n",
        "std_sales = df_train.groupby(['store_nbr', 'item_nbr'])['unit_sales'].transform('std')"
      ],
      "metadata": {
        "id": "QbYM3gGuHOmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Avoid division by zero by replacing 0 std with 1 (and fill NaNs with 1)\n",
        "std_sales = std_sales.replace(0, 1).fillna(1)"
      ],
      "metadata": {
        "id": "7ZkVLeB5l7RJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Z-score for each sale\n",
        "df_train['z_score'] = (df_train['unit_sales'] - mean_sales) / std_sales"
      ],
      "metadata": {
        "id": "VozS_4H_l7OR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the threshold for outliers (Z-score > 5 indicates an extreme outlier)\n",
        "outliers = df_train[df_train['z_score'] > 5]\n",
        "print(f\"Number of outliers detected (Z-score > 5): {len(outliers)}\")"
      ],
      "metadata": {
        "id": "oyTP-oSpl7MM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few outliers for inspection\n",
        "outliers.head()"
      ],
      "metadata": {
        "id": "XBbYQzovl7I0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df_train[df_train['z_score'] <= 5]"
      ],
      "metadata": {
        "id": "u0Uaw5BB0jsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape"
      ],
      "metadata": {
        "id": "Kd_5QL4c0mvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Fill missing dates with zero sales"
      ],
      "metadata": {
        "id": "Jw1DCSw9IBwN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'date' column to datetime format\n",
        "df_train['date'] = pd.to_datetime(df_train['date'])\n",
        "\n",
        "# Get the minimum and maximum dates in the dataset to create a full date range\n",
        "min_date = df_train['date'].min()\n",
        "max_date = df_train['date'].max()\n",
        "\n",
        "# Generate a full date range from min_date to max_date (daily frequency)\n",
        "full_date_range = pd.DataFrame({'date': pd.date_range(min_date, max_date, freq='D')})\n",
        "\n",
        "# Create a DataFrame with all (store, item, date) combinations by merging store-item pairs with full date range\n",
        "store_item_combinations = df_train[['store_nbr', 'item_nbr']].drop_duplicates()\n",
        "all_combinations = store_item_combinations.merge(full_date_range, how='cross')\n",
        "\n",
        "# Merge the full combinations with the original df_train to fill in missing sales for specific dates\n",
        "df_filled = all_combinations.merge(df_train, on=['store_nbr', 'item_nbr', 'date'], how='left')\n",
        "\n",
        "# Fill missing sales values with 0 (for days with no sales)\n",
        "df_filled['unit_sales'] = df_filled['unit_sales'].fillna(0)\n",
        "\n",
        "# Increase maximum column width and show all columns\n",
        "pd.set_option('display.max_columns', None)  # Show all columns\n",
        "pd.set_option('display.width', 200)         # Widen total display width (characters)\n",
        "pd.set_option('display.max_colwidth', 50)   # Increase column content width\n",
        "\n",
        "# Check the first few rows of the filled DataFrame\n",
        "print(df_filled.head())"
      ],
      "metadata": {
        "id": "BwlVEonzHRWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filled.head()"
      ],
      "metadata": {
        "id": "ybksePiplVtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filled.shape"
      ],
      "metadata": {
        "id": "SSwXK6ZKlZRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filled.describe()"
      ],
      "metadata": {
        "id": "TDECzmQ-Amnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filled.isna().sum()"
      ],
      "metadata": {
        "id": "VZm2wSM-Aq0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Drop unnecessary columns"
      ],
      "metadata": {
        "id": "EQJ1lcGcmSt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filled = df_filled.drop(columns=['onpromotion']) # drop the onpromotion column\n",
        "df_filled = df_filled.drop(columns=['z_score']) # drop the z_score column\n",
        "df_filled = df_filled.drop(columns=['id']) # drop the id column\n",
        "df_filled = df_filled.drop(columns=['perishable'])\n",
        "#df_filled = df_filled.drop(columns=['family'])\n",
        "df_filled = df_filled.drop(columns=['class'])"
      ],
      "metadata": {
        "id": "nYZ6W0Lweupf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recheck Data after dropping columns"
      ],
      "metadata": {
        "id": "snPvTkm2mcBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filled.isna().sum()"
      ],
      "metadata": {
        "id": "xDttG1shwNxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filled.info()"
      ],
      "metadata": {
        "id": "6Eb0Yn72e8hO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filled.head()"
      ],
      "metadata": {
        "id": "5EhCITpCaEk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering"
      ],
      "metadata": {
        "id": "-hk9vTdiV7Ia"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create New time-based features"
      ],
      "metadata": {
        "id": "UzKXZb3Nmmjx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrgN8Cnyfehv"
      },
      "outputs": [],
      "source": [
        "df_filled[\"year\"] = df_filled[\"date\"].dt.year"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_filled[\"month\"] = df_filled[\"date\"].dt.month"
      ],
      "metadata": {
        "id": "_RtOI6l4m1KI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filled[\"day\"] = df_filled[\"date\"].dt.day"
      ],
      "metadata": {
        "id": "_tV_TOJ1m1Hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filled[\"day_of_week\"] = df_filled[\"date\"].dt.dayofweek"
      ],
      "metadata": {
        "id": "1sTs3OdXm1FJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z_695gV4m1AM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create lag features (previous sales)"
      ],
      "metadata": {
        "id": "MT7MSrJ1mrab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filled[\"lag_1\"] = df_filled.groupby([\"store_nbr\", \"item_nbr\"])[\"unit_sales\"].shift(1)"
      ],
      "metadata": {
        "id": "yn-f9lzomh99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filled[\"lag_7\"] = df_filled.groupby([\"store_nbr\", \"item_nbr\"])[\"unit_sales\"].shift(7)"
      ],
      "metadata": {
        "id": "oiUbDsA5m6AP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filled[\"lag_14\"] = df_filled.groupby([\"store_nbr\", \"item_nbr\"])[\"unit_sales\"].shift(14)"
      ],
      "metadata": {
        "id": "eN9-7YrDm59J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filled[\"lag_30\"] = df_filled.groupby([\"store_nbr\", \"item_nbr\"])[\"unit_sales\"].shift(14)"
      ],
      "metadata": {
        "id": "cibGDL_uw6jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rolling average of unit sales"
      ],
      "metadata": {
        "id": "437riaqvmus3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filled[\"rolling_avg_7\"] = (df_filled.groupby([\"store_nbr\", \"item_nbr\"])[\"unit_sales\"].transform(lambda x: x.rolling(window=7, min_periods=1).mean()))\n"
      ],
      "metadata": {
        "id": "yfW8yomJmh7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filled[\"rolling_stdv_7\"] = (df_filled.groupby([\"store_nbr\", \"item_nbr\"])[\"unit_sales\"].transform(lambda x: x.rolling(window=7, min_periods=1).std()))\n"
      ],
      "metadata": {
        "id": "nOLjqmMMm9Ih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fill missing values using forward fill"
      ],
      "metadata": {
        "id": "nECDO2fknVoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filled = df_filled.fillna(method ='ffill')"
      ],
      "metadata": {
        "id": "tVpdfjsHmh4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vpk1TNyOnMQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Drop rows with NaN values after creating lag features"
      ],
      "metadata": {
        "id": "tbfbei4Dm-Nh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filled.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "XICffUnBmh15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check Dataset after Feature Engineering"
      ],
      "metadata": {
        "id": "N_L52nd_nGPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filled.head()"
      ],
      "metadata": {
        "id": "ED93YAnUmhyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filled.shape"
      ],
      "metadata": {
        "id": "yxINK97Gfh4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Final Dataset"
      ],
      "metadata": {
        "id": "kUZ-0bMcnh7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df_filled.to_csv('final_data_guayas_region_20250812.csv', index=False)\n",
        "#files.download('final_data_guayas_region_20250812.csv')"
      ],
      "metadata": {
        "id": "5CWhokf6vzjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filled.to_pickle(\"/content/drive/MyDrive/retail_kaggle_data/final_data_guayas_region_20250815.pkl\")\n"
      ],
      "metadata": {
        "id": "p-ryM1IawwL8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}